{
  "type": "hyp",
  "text": "The effects of red orpiment on cell morphology and expression of PML mRNA and protein were not observed in NB4 cells.\n",
  "self": {
    "NER": {
      "answers": [
        "PML",
        "NB4"
      ],
      "QG_hash=ThomasNLG/t5-qg_squad1-en": {
        "questions": [
          "What protein and mRNA were not affected by red orpiment?",
          "What type of cells did not show any effects of red orpiment?"
        ]
      }
    },
    "NOUN": {
      "answers": [
        "The effects",
        "red orpiment",
        "cell morphology",
        "expression",
        "PML mRNA",
        "protein",
        "NB4 cells"
      ],
      "QG_hash=ThomasNLG/t5-qg_squad1-en": {
        "questions": [
          "What was not observed in NB4 cells?",
          "What was not observed in NB4 cells?",
          "What did the red orpiment not affect?",
          "What did the red orpiment not affect?",
          "What protein was not affected by red orpiment?",
          "What is the main component of PML?",
          "What type of cells did not show any effects of red orpiment?"
        ]
      }
    }
  },
  "asked": {
    "What mRNA did the rat not express after treatment with ATRA or quercet": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.2514793276786804,
        "ground_truth": {
          "PML": {
            "bertscore": 0.6862248778343201,
            "f1": 0
          }
        }
      }
    },
    "How many cell lines were tested for the presence of ATRA?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.0018090605735778809,
        "ground_truth": {
          "three": {
            "bertscore": 0.7179227471351624,
            "f1": 0
          }
        }
      }
    },
    "What was used to treat the swine flu?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.0004957914352416992,
        "ground_truth": {
          "ATRA": {
            "bertscore": 0.6899303793907166,
            "f1": 0
          }
        }
      }
    },
    "What did the treatment with ATRA or quercetin not change?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.041418373584747314,
        "ground_truth": {
          "The expression": {
            "bertscore": 0.6652610301971436,
            "f1": 0
          }
        }
      }
    },
    "What did the expression of PML not change after treatment with ATRA or quercetin": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.12800323963165283,
        "ground_truth": {
          "mRNA": {
            "bertscore": 0.6875342726707458,
            "f1": 0
          }
        }
      }
    },
    "What was the effect of ATRA on the expression of PML mRNA?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.004019498825073242,
        "ground_truth": {
          "no change": {
            "bertscore": 0.7178478837013245,
            "f1": 0
          }
        }
      }
    },
    "How many cells were treated with ATRA or quercetin?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.0014345049858093262,
        "ground_truth": {
          "all the three cell lines": {
            "bertscore": 0.6818884611129761,
            "f1": 0
          }
        }
      }
    },
    "What did the expression of PML mRNA not change after?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.08880555629730225,
        "ground_truth": {
          "treatment": {
            "bertscore": 0.6978253722190857,
            "f1": 0
          }
        }
      }
    },
    "What drug did the mRNA expression of PML not change after treatment?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.2897300124168396,
        "ground_truth": {
          "quercetin": {
            "bertscore": 0.6064949035644531,
            "f1": 0
          }
        }
      }
    }
  }
}