{
  "type": "hyp",
  "text": "While hilD expression was reduced in the mlc mutant it was slightly higher than the wild-type level in both the hilE and hilE/\n",
  "self": {
    "NER": {
      "answers": [],
      "QG_hash=ThomasNLG/t5-qg_squad1-en": {
        "questions": []
      }
    },
    "NOUN": {
      "answers": [
        "hilD expression",
        "the mlc mutant",
        "it",
        "the wild-type level",
        "both the hilE",
        "hilE/"
      ],
      "QG_hash=ThomasNLG/t5-qg_squad1-en": {
        "questions": [
          "What was reduced in the mlc mutant?",
          "Which mutant had a lower hilD expression?",
          "What was the expression level of hilD in the mlc mutant?",
          "What was the expression level of hilD in both hilE and h",
          "In what two mutants was hilD expression slightly higher than the wild-type?",
          "What is the wild-type hilD?"
        ]
      }
    }
  },
  "asked": {
    "What gene does repress hilE expression?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.36681944131851196,
        "ground_truth": {
          "Mlc": {
            "bertscore": 0.6736112833023071,
            "f1": 0
          }
        }
      }
    },
    "What is the mechanism by which Mlc activates SPI1 gene expression?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.006687581539154053,
        "ground_truth": {
          "We": {
            "bertscore": 0.6054113507270813,
            "f1": 0
          }
        }
      }
    },
    "What does Mlc activate?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.0006350874900817871,
        "ground_truth": {
          "SPI1 gene expression": {
            "bertscore": 0.6025294661521912,
            "f1": 0
          }
        }
      }
    },
    "What does Mlc repress?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.23959684371948242,
        "ground_truth": {
          "hilE expression": {
            "bertscore": 0.6658812761306763,
            "f1": 0
          }
        }
      }
    }
  }
}