{
  "type": "hyp",
  "text": "Remarkably NleH1 reduced both tyrosine phosphorylation and serine phosphorylation of RPS3 (Fig.\n",
  "self": {
    "NER": {
      "answers": [
        "Remarkably NleH1"
      ],
      "QG_hash=ThomasNLG/t5-qg_squad1-en": {
        "questions": [
          "What reduced both tyrosine phosphorylation and serine phosphorylation"
        ]
      }
    },
    "NOUN": {
      "answers": [
        "NleH1",
        "both tyrosine phosphorylation",
        "serine phosphorylation",
        "RPS3",
        "Fig"
      ],
      "QG_hash=ThomasNLG/t5-qg_squad1-en": {
        "questions": [
          "What reduced both tyrosine phosphorylation and serine phosphorylation",
          "What did NleH1 reduce?",
          "What did NleH1 reduce in RPS3?",
          "What protein was reduced by NleH1?",
          "What is the result of NleH1's effect on RPS3?"
        ]
      }
    }
  },
  "asked": {
    "What did we not detect in RPS3?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.0027631521224975586,
        "ground_truth": {
          "We": {
            "bertscore": 0.6054112315177917,
            "f1": 0
          }
        }
      }
    },
    "What did we not detect?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.0009546875953674316,
        "ground_truth": {
          "tyrosine- or threonine-phosphorylation": {
            "bertscore": 0.5943582057952881,
            "f1": 0
          }
        }
      }
    },
    "What protein was not detected in the cytosolic model?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.0017711520195007324,
        "ground_truth": {
          "RPS3": {
            "bertscore": 0.6660844087600708,
            "f1": 0
          }
        }
      }
    },
    "What is the phosphorylation of RPS3?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "serine",
        "answerability": 0.9681132435798645,
        "ground_truth": {
          "(Fig": {
            "bertscore": 0.6550253033638,
            "f1": 0
          }
        }
      }
    }
  }
}