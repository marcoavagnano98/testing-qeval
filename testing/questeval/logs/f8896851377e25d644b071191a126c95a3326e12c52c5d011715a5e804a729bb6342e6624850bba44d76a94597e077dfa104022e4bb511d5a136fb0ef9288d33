{
  "type": "hyp",
  "text": "In P. aeruginosa resistance to CAPs is inducible by the PmrAB two-component regulatory system PmrAB.\n",
  "self": {
    "NER": {
      "answers": [
        "P. aeruginosa",
        "PmrAB",
        "two",
        "PmrAB"
      ],
      "QG_hash=ThomasNLG/t5-qg_squad1-en": {
        "questions": [
          "What is the two component regulatory system of PmrAB?",
          "What is the name of the two component regulatory system that inducibles resistance to CAP",
          "How many components are in the PmrAB regulatory system?",
          "What is the name of the two component regulatory system that inducibles resistance to CAP"
        ]
      }
    },
    "NOUN": {
      "answers": [
        "P. aeruginosa resistance",
        "CAPs",
        "the PmrAB two-component regulatory system",
        "PmrAB"
      ],
      "QG_hash=ThomasNLG/t5-qg_squad1-en": {
        "questions": [
          "What is inducible by the two-component regulatory system PmrAB?",
          "What is the PmrAB two component regulatory system?",
          "What makes resistance to CAPs inducible in P. aeruginosa",
          "What is the name of the two component regulatory system that inducibles resistance to CAP"
        ]
      }
    }
  },
  "asked": {
    "What is the resistance to CAPs inducible by?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "P. aeruginosa",
        "answerability": 0.8637094497680664,
        "ground_truth": {
          "P. aeruginosa": {
            "bertscore": 1.0,
            "f1": 1.0
          }
        }
      }
    },
    "What is the name of the protein that induces resistance to CAPs?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.4603186249732971,
        "ground_truth": {
          "PhoPQ": {
            "bertscore": 0.6435238718986511,
            "f1": 0
          }
        }
      }
    },
    "What is the TCS of P. aeruginosa that is inducible": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.1592077612876892,
        "ground_truth": {
          "PmrAB": {
            "bertscore": 0.6613537073135376,
            "f1": 0
          }
        }
      }
    },
    "What is the limiting Mg2+ level?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.00028628110885620117,
        "ground_truth": {
          "43": {
            "bertscore": 0.5876714587211609,
            "f1": 0
          }
        }
      }
    },
    "What is inducible by the PhoPQ and PmrAB TCSs": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.07434815168380737,
        "ground_truth": {
          "P. aeruginosa resistance": {
            "bertscore": 0.611220121383667,
            "f1": 0
          }
        }
      }
    },
    "What is the resistance to in P. aeruginosa?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "CAPs",
        "answerability": 0.8995503783226013,
        "ground_truth": {
          "CAPs": {
            "bertscore": 1.0,
            "f1": 1.0
          }
        }
      }
    },
    "What are the two main components of resistance to CAPs?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.016646981239318848,
        "ground_truth": {
          "the PhoPQ and PmrAB TCSs": {
            "bertscore": 0.5892603993415833,
            "f1": 0
          }
        }
      }
    },
    "What is the PhoPQ and PmrAB TCSs inducible in": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.07305145263671875,
        "ground_truth": {
          "response": {
            "bertscore": 0.7024294137954712,
            "f1": 0
          }
        }
      }
    },
    "What is the limiting element of P. aeruginosa?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.016638338565826416,
        "ground_truth": {
          "Mg2": {
            "bertscore": 0.6044813990592957,
            "f1": 0
          }
        }
      }
    }
  }
}