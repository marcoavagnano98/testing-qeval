{
  "type": "hyp",
  "text": "While hilE expression was reduced in the mlc mutant it was slightly higher than the wild-type level in both the hilE and hilE/\n",
  "self": {
    "NER": {
      "answers": [],
      "QG_hash=ThomasNLG/t5-qg_squad1-en": {
        "questions": []
      }
    },
    "NOUN": {
      "answers": [
        "expression",
        "the mlc mutant",
        "it",
        "the wild-type level",
        "both the hilE",
        "hilE/"
      ],
      "QG_hash=ThomasNLG/t5-qg_squad1-en": {
        "questions": [
          "What was reduced in the mlc mutant?",
          "What mutant had a lower hilE expression?",
          "What was the expression level of hilE in the mlc mutant?",
          "What was the hilE expression level in the mlc mutant?",
          "What gene expression was slightly higher than the wild-type?",
          "What was the wild-type hilE?"
        ]
      }
    }
  },
  "asked": {
    "What gene does repress hilE expression?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "mlc mutant",
        "answerability": 0.5988260507583618,
        "ground_truth": {
          "Mlc": {
            "bertscore": 0.7555869221687317,
            "f1": 0.6666666666666666
          }
        }
      }
    },
    "What is the mechanism by which Mlc activates SPI1 gene expression?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.007586658000946045,
        "ground_truth": {
          "We": {
            "bertscore": 0.6054113507270813,
            "f1": 0
          }
        }
      }
    },
    "What does Mlc activate?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.0005580782890319824,
        "ground_truth": {
          "SPI1 gene expression": {
            "bertscore": 0.6025294661521912,
            "f1": 0
          }
        }
      }
    },
    "What does Mlc repress?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.2734299898147583,
        "ground_truth": {
          "hilE expression": {
            "bertscore": 0.6658812761306763,
            "f1": 0
          }
        }
      }
    }
  }
}