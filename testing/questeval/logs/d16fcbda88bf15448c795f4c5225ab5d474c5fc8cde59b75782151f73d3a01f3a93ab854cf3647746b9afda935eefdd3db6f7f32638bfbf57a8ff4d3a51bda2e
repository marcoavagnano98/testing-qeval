{
  "type": "hyp",
  "text": "Expression of Rab5a was GTPase-sensitive and did not block VEGFR2 trafficking.\n",
  "self": {
    "NER": {
      "answers": [],
      "QG_hash=ThomasNLG/t5-qg_squad1-en": {
        "questions": []
      }
    },
    "NOUN": {
      "answers": [
        "Expression",
        "Rab5a",
        "VEGFR2 trafficking"
      ],
      "QG_hash=ThomasNLG/t5-qg_squad1-en": {
        "questions": [
          "What was GTPase sensitive?",
          "What gene was not able to block VEGFR2 trafficking?",
          "What did Rab5a not block?"
        ]
      }
    }
  },
  "asked": {
    "What does GTP-bound Rab5a mutants block?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.0036742091178894043,
        "ground_truth": {
          "Expression": {
            "bertscore": 0.7109297513961792,
            "f1": 0
          }
        }
      }
    },
    "What is the name of the gene that blocks VEGFR2 trafficking and degradation?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.0131874680519104,
        "ground_truth": {
          "GTP": {
            "bertscore": 0.6902484893798828,
            "f1": 0
          }
        }
      }
    },
    "What block the activity of VEGFR2?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.18891048431396484,
        "ground_truth": {
          "Rab5a mutants": {
            "bertscore": 0.6376035213470459,
            "f1": 0
          }
        }
      }
    },
    "What does GTP block?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.0022602081298828125,
        "ground_truth": {
          "VEGFR2 trafficking": {
            "bertscore": 0.6477409601211548,
            "f1": 0
          }
        }
      }
    },
    "What does the expression of GTP-bound Rab5a mutants block?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.010535955429077148,
        "ground_truth": {
          "degradation": {
            "bertscore": 0.7194915413856506,
            "f1": 0
          }
        }
      }
    }
  }
}