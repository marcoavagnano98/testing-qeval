{
  "type": "hyp",
  "text": "As seen in Figure 2B the induction of rv2623 was also observed following phagocytosis by macrophages 11.\n",
  "self": {
    "NER": {
      "answers": [
        "rv2623"
      ],
      "QG_hash=ThomasNLG/t5-qg_squad1-en": {
        "questions": [
          "What is the name of the protein that is induction by macrophages?"
        ]
      }
    },
    "NOUN": {
      "answers": [
        "Figure",
        "the induction",
        "rv2623",
        "phagocytosis",
        "macrophages"
      ],
      "QG_hash=ThomasNLG/t5-qg_squad1-en": {
        "questions": [
          "What is the induction of rv2623?",
          "What was observed following phagocytosis?",
          "What is the name of the protein that is induction by macrophages?",
          "What is the process that causes the induction of rv2623?",
          "What is the phagocytosis of rv2623?"
        ]
      }
    }
  },
  "asked": {
    "What is the name of the protein that is induced by a bacterium?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "rv2623",
        "answerability": 0.5369769930839539,
        "ground_truth": {
          "rv2623": {
            "bertscore": 1.0,
            "f1": 1.0
          }
        }
      }
    },
    "What suggests that the induction of rv2623 may have biological relevance?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.04022294282913208,
        "ground_truth": {
          "These latter observations": {
            "bertscore": 0.6360556483268738,
            "f1": 0
          }
        }
      }
    },
    "What does the rv2623 have biological relevance?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.0016439557075500488,
        "ground_truth": {
          "the induction": {
            "bertscore": 0.6973353028297424,
            "f1": 0
          }
        }
      }
    },
    "What do the results of the rv2623 induction suggest?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.01094287633895874,
        "ground_truth": {
          "biological relevance": {
            "bertscore": 0.7150477766990662,
            "f1": 0
          }
        }
      }
    }
  }
}