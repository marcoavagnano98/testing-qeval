{
  "type": "hyp",
  "text": "Our results show that synchronized hair follicle cycling in adolescent C57BL/6 mice is associated with substantial angiogenesis and that inhibiting angiogenesis in vivo by the intraperitoneal application of a fumagillin derivative retards experimentally induced anagen development in these mice.\n",
  "self": {
    "NER": {
      "answers": [
        "vivo"
      ],
      "QG_hash=ThomasNLG/t5-qg_squad1-en": {
        "questions": [
          "In what way does the application of fumagillin derivative retard anagen development?"
        ]
      }
    },
    "NOUN": {
      "answers": [
        "Our results",
        "hair follicle cycling",
        "adolescent C57BL/6 mice",
        "substantial angiogenesis",
        "angiogenesis",
        "vivo",
        "the intraperitoneal application",
        "a fumagillin derivative retards",
        "anagen development",
        "these mice"
      ],
      "QG_hash=ThomasNLG/t5-qg_squad1-en": {
        "questions": [
          "What shows that synchronized hair follicle cycling is associated with substantial angiogenesis",
          "What is associated with substantial angiogenesis?",
          "What type of mice have significant angiogenesis?",
          "What is synchronized hair follicle cycling associated with?",
          "What is synchronized hair follicle cycling associated with?",
          "In what way does the application of fumagillin derivative retard anagen development?",
          "What is the most effective way to inhibit angiogenesis in vivo?",
          "What is the cause of anagen development in C57BL/6 mice?",
          "What does inhibiting angiogenesis in vivo cause?",
          "What is inhibited by the intraperitoneal application of fumagillin derivative?"
        ]
      }
    }
  },
  "asked": {
    "What is DMBA?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.005522370338439941,
        "ground_truth": {
          "712-dimethylbenzaanthracene": {
            "bertscore": 0.5718095302581787,
            "f1": 0
          }
        }
      }
    },
    "What was studied in hamsters after carcinogenesis?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.003470003604888916,
        "ground_truth": {
          "Effects": {
            "bertscore": 0.6883600950241089,
            "f1": 0
          }
        }
      }
    },
    "What was the main cause of the changes in the cheek pouch epithelium?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.009237110614776611,
        "ground_truth": {
          "repeated low-level X radiation": {
            "bertscore": 0.6686145067214966,
            "f1": 0
          }
        }
      }
    },
    "What did DMBA cause in hamsters?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.0007457137107849121,
        "ground_truth": {
          "functional microvascular changes": {
            "bertscore": 0.6672928929328918,
            "f1": 0
          }
        }
      }
    },
    "What did DMBA cause to be altered?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.00787431001663208,
        "ground_truth": {
          "hamster cheek pouch epithelium": {
            "bertscore": 0.6484948992729187,
            "f1": 0
          }
        }
      }
    },
    "What is the name of the process that causes a hamster to develop a tumor": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.05266773700714111,
        "ground_truth": {
          "carcinogenesis": {
            "bertscore": 0.6772279739379883,
            "f1": 0
          }
        }
      }
    },
    "What is the name of the chemical that causes carcinogenesis in hamsters?": {
      "QA_hash=ThomasNLG/t5-qa_squad2neg-en": {
        "answer": "unanswerable",
        "answerability": 0.0012034177780151367,
        "ground_truth": {
          "(DMBA": {
            "bertscore": 0.6746246218681335,
            "f1": 0
          }
        }
      }
    }
  }
}